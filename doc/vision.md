# Техническое видение проекта

## 1. Технологии

- Язык программирования: Python
- Telegram Bot API: библиотека aiogram
- LLM: через OpenRouter с использованием реализации openai client
- Хранение истории диалога: простые структуры Python (dict/list)
- Деплой: Docker
- Логирование: стандартный logging из Python
- Конфигурирование: .env файл с переменными окружения (токен бота, ключ API LLM и др.)
- Тестирование: pytest
- Управление зависимостями и окружением: uv
- Автоматизация сборки, запуска и тестирования: make 

## 2. Принцип разработки

- Минимально жизнеспособный продукт (MVP): реализуем только базовые функции для проверки гипотезы.
- KISS (Keep It Simple, Stupid): избегаем сложных архитектурных решений и оверинжиниринга.
- Итеративная разработка: быстрые короткие циклы — реализовали, проверили, улучшили.
- Чистый и читаемый код, минимум зависимостей.
- Все настройки — через переменные окружения.
- Покрытие ключевой логики простыми тестами (pytest).
- Документирование только самого необходимого (README, vision.md).
- Архитектура без ООП: проектирование через простые функции, минимальное использование классов. 

## 3. Структура проекта

```
main.py
├── config.py
├── bot/
│   └── handlers.py
├── llm/
│   ├── client.py
│   ├── prompts.py
│   └── memory.py
├── logging (стандартный logging)
├── test/
├── doc/
├── pyproject.toml
├── .env.example
├── Dockerfile
└── Makefile
```

- Вся логика — через функции, без классов.
- История диалога — в llm/memory.py (dict/list).
- Взаимодействие с LLM — через llm/client.py (OpenRouter, openai client).
- Обработка сообщений Telegram — в bot/handlers.py (aiogram).
- Конфигурирование — через config.py и .env.
- Логирование — стандартный logging.
- Тесты — в test/.

## 4. Архитектура проекта

- **Функциональный подход**: вся логика реализована через функции, минимальное использование классов.
- **Компонентный подход**: разделение на независимые компоненты (bot, llm, config, memory) с чёткими интерфейсами.
- **Модульность**: разделение на модули по ответственности (bot/, llm/).
- **Асинхронность**: использование aiogram для асинхронной обработки сообщений Telegram.
- **In-memory хранение**: история диалога в оперативной памяти, без БД.
- **Конфигурация через переменные окружения**: все настройки в .env файле.
- **Простое логирование**: стандартный logging из Python.
- **Отсутствие сложных паттернов**: никаких DI, ORM, сложных абстракций.
- **Схема взаимодействие**: компоненты вызывают друг друга напрямую через функции.

**Прямая схема (запрос):**
```
[Telegram] → [bot/handlers.py] → [llm/client.py] → [OpenRouter API]
                ↓                      ↓
            [config.py]           [llm/memory.py]
                ↓                      ↓
            [.env]                [История диалога]
```

**Обратная схема (ответ):**
```
[OpenRouter API] → [llm/client.py] → [bot/handlers.py] → [Telegram]
                        ↓                      ↓
                [llm/memory.py]           [logging]
                        ↓                      ↓
                [История диалога]        [Логи событий]
```

## 5. Модель данных

- История диалога каждого пользователя хранится в оперативной памяти (dict).
- Ключ — user_id (или chat_id), значение — список сообщений (list of dict).
- Формат одного сообщения:
  - role: str (user/assistant/system)
  - content: str (текст сообщения)
  - timestamp: datetime (опционально, для отладки)
- Пример структуры:
  ```python
    {
        "chat_id": 123456789,
        "messages": [
            {"role": "system", "content": "Ты консультант компании...", "timestamp": ...},
            {"role": "user", "content": "Привет", "timestamp": ...},
            {"role": "assistant", "content": "Здравствуйте!", "timestamp": ...},
            ...
        ]
    }
  ```
- После перезапуска приложения история теряется (без БД).

## 6. Работа с LLM

- Используем OpenRouter API через openai client.
- Системный промпт содержит информацию о компании и услугах.
- Каждый запрос включает:
  - Системный промпт (роль бота, контекст компании)
  - История диалога пользователя (последние N сообщений)
  - Текущее сообщение пользователя
- Ограничения:
  - Максимальная длина истории (например, последние 10 сообщений)
  - Таймаут запросов (например, 30 секунд)
  - Обработка ошибок API (повторные попытки, fallback)
- Промпты хранятся в llm/prompts.py как простые строки. 

## 7. Мониторинг LLM

- Логирование всех запросов к LLM (входные данные, ответы, ошибки). 

## 8. Сценарии работы

- **Старт диалога**: пользователь отправляет /start или первое сообщение, бот приветствует и представляется.
- **Предложение услуг**: бот анализирует запрос пользователя и предлагает подходящие услуги компании.

## 9. Деплой

- Docker-контейнер с Python-приложением.
- Переменные окружения для конфигурации (токены, ключи API).
- Простой процесс развертывания: сборка образа и запуск контейнера.
- Локальный запуск на своей машине через Docker.
- Makefile для автоматизации сборки и запуска. 

## 10. Подход к конфигурированию

- Все настройки через переменные окружения (.env файл).
- Обязательные параметры: токен Telegram-бота, ключ API OpenRouter.
- Опциональные параметры: модель LLM, таймауты, настройки логирования.
- Пример файла .env.example с описанием всех параметров.

## 11. Подход к логгированию

- Стандартный logging из Python.
- Логирование в файл и консоль.
- Уровни логирования: INFO, ERROR, DEBUG.
- Логирование всех запросов к LLM (входные данные, ответы, ошибки).
- Логирование событий Telegram-бота (входящие сообщения, отправленные ответы). 